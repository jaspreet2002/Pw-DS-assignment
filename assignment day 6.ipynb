{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c368293c-6747-4a13-b4f0-77eb869b5856",
   "metadata": {},
   "source": [
    "1. Data Ingestion Pipeline:\n",
    "   a. Design a data ingestion pipeline that collects and stores data from various sources such as databases, APIs, and streaming platforms.\n",
    "   b. Implement a real-time data ingestion pipeline for processing sensor data from IoT devices.\n",
    "   c. Develop a data ingestion pipeline that handles data from different file formats (CSV, JSON, etc.) and performs data validation and cleansing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83553431-9cff-4033-aa89-de1f776622c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from zipfile import Path\n",
    "from src.constant import *\n",
    "from src.exception import CustomException\n",
    "from src.logger import logging\n",
    "from src.utils.main_utils import MainUtils\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataIngestionConfig:\n",
    "    artifact_folder: str = os.path.join(artifact_folder)\n",
    "    \n",
    "        \n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.data_ingestion_config = DataIngestionConfig()\n",
    "        self.utils = MainUtils()\n",
    "\n",
    "\n",
    "    def export_collection_as_dataframe(self,collection_name, db_name):\n",
    "        try:\n",
    "            mongo_client = MongoClient(MONGO_DB_URL)\n",
    "\n",
    "            collection = mongo_client[db_name][collection_name]\n",
    "\n",
    "            df = pd.DataFrame(list(collection.find()))\n",
    "\n",
    "            if \"_id\" in df.columns.to_list():\n",
    "                df = df.drop(columns=[\"_id\"], axis=1)\n",
    "\n",
    "            df.replace({\"na\": np.nan}, inplace=True)\n",
    "\n",
    "            return df\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "        \n",
    "    def export_data_into_feature_store_file_path(self)->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Method Name :   export_data_into_feature_store\n",
    "        Description :   This method reads data from mongodb and saves it into artifacts. \n",
    "        \n",
    "        Output      :   dataset is returned as a pd.DataFrame\n",
    "        On Failure  :   Write an exception log and then raise an exception\n",
    "        \n",
    "        Version     :   0.1\n",
    "       \n",
    "        \"\"\"\n",
    "        try:\n",
    "            logging.info(f\"Exporting data from mongodb\")\n",
    "            raw_file_path  = self.data_ingestion_config.artifact_folder\n",
    "            os.makedirs(raw_file_path,exist_ok=True)\n",
    "\n",
    "            sensor_data = self.export_collection_as_dataframe(\n",
    "                                                              collection_name= MONGO_COLLECTION_NAME,\n",
    "                                                              db_name = MONGO_DATABASE_NAME)\n",
    "            \n",
    "\n",
    "            logging.info(f\"Saving exported data into feature store file path: {raw_file_path}\")\n",
    "        \n",
    "            feature_store_file_path = os.path.join(raw_file_path,'wafer_fault.csv')\n",
    "            sensor_data.to_csv(feature_store_file_path,index=False)\n",
    "           \n",
    "\n",
    "            return feature_store_file_path\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e,sys)\n",
    "\n",
    "    def initiate_data_ingestion(self) -> Path:\n",
    "        \"\"\"\n",
    "            Method Name :   initiate_data_ingestion\n",
    "            Description :   This method initiates the data ingestion components of training pipeline \n",
    "            \n",
    "            Output      :   train set and test set are returned as the artifacts of data ingestion components\n",
    "            On Failure  :   Write an exception log and then raise an exception\n",
    "            \n",
    "            Version     :   1.2\n",
    "            Revisions   :   moved setup to cloud\n",
    "        \"\"\"\n",
    "        logging.info(\"Entered initiate_data_ingestion method of Data_Ingestion class\")\n",
    "\n",
    "        try:\n",
    "            \n",
    "            feature_store_file_path = self.export_data_into_feature_store_file_path()\n",
    "\n",
    "            logging.info(\"Got the data from mongodb\")\n",
    "\n",
    "\n",
    "            logging.info(\n",
    "                \"Exited initiate_data_ingestion method of Data_Ingestion class\"\n",
    "            )\n",
    "            \n",
    "            return feature_store_file_path\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys) from e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa555c5-af08-4faf-8fe8-af2f255faaa5",
   "metadata": {},
   "source": [
    "2. Model Training:\n",
    "   a. Build a machine learning model to predict customer churn based on a given dataset. Train the model using appropriate algorithms and evaluate its performance.\n",
    "   b. Develop a model training pipeline that incorporates feature engineering techniques such as one-hot encoding, feature scaling, and dimensionality reduction.\n",
    "   c. Train a deep learning model for image classification using transfer learning and fine-tuning techniques.\n",
    "\n",
    "3. Model Validation:\n",
    "   a. Implement cross-validation to evaluate the performance of a regression model for predicting housing prices.\n",
    "   b. Perform model validation using different evaluation metrics such as accuracy, precision, recall, and F1 score for a binary classification problem.\n",
    "   c. Design a model validation strategy that incorporates stratified sampling to handle imbalanced datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e722290-c9aa-48db-a4dc-4ba59850ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import Generator, List, Tuple\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from src.constant import *\n",
    "from src.exception import CustomException\n",
    "from src.logger import logging\n",
    "from src.utils.main_utils import MainUtils\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ModelTrainerConfig:\n",
    "    artifact_folder= os.path.join(artifact_folder)\n",
    "    trained_model_path= os.path.join(artifact_folder,\"model.pkl\" )\n",
    "    expected_accuracy=0.45\n",
    "    model_config_file_path= os.path.join('config','model.yaml')\n",
    "\n",
    "\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self):\n",
    "        \n",
    "\n",
    "        self.model_trainer_config = ModelTrainerConfig()\n",
    "\n",
    "\n",
    "        self.utils = MainUtils()\n",
    "\n",
    "        self.models = {\n",
    "                        'XGBClassifier': XGBClassifier(),\n",
    "                        'GradientBoostingClassifier' : GradientBoostingClassifier(),\n",
    "                        'SVC' : SVC(),\n",
    "                        'RandomForestClassifier': RandomForestClassifier()\n",
    "                        }\n",
    "\n",
    "    \n",
    "    def evaluate_models(self, X, y, models):\n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42\n",
    "            )\n",
    "\n",
    "            report = {}\n",
    "\n",
    "            for i in range(len(list(models))):\n",
    "                model = list(models.values())[i]\n",
    "\n",
    "                model.fit(X_train, y_train)  # Train model\n",
    "\n",
    "                y_train_pred = model.predict(X_train)\n",
    "\n",
    "                y_test_pred = model.predict(X_test)\n",
    "\n",
    "                train_model_score = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "                test_model_score = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "                report[list(models.keys())[i]] = test_model_score\n",
    "\n",
    "            return report\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "\n",
    "    def get_best_model(self,\n",
    "                    x_train:np.array, \n",
    "                    y_train: np.array,\n",
    "                    x_test:np.array, \n",
    "                    y_test: np.array):\n",
    "        try:\n",
    "            \n",
    "             \n",
    "\n",
    "            model_report: dict = self.evaluate_models(\n",
    "                 x_train =  x_train, \n",
    "                 y_train = y_train, \n",
    "                 x_test =  x_test, \n",
    "                 y_test = y_test, \n",
    "                 models = self.models\n",
    "            )\n",
    "\n",
    "            print(model_report)\n",
    "\n",
    "            best_model_score = max(sorted(model_report.values()))\n",
    "\n",
    "            ## To get best model name from dict\n",
    "\n",
    "            best_model_name = list(model_report.keys())[\n",
    "                list(model_report.values()).index(best_model_score)\n",
    "            ]\n",
    "\n",
    "            best_model_object = self.models[best_model_name]\n",
    "\n",
    "\n",
    "            return best_model_name, best_model_object, best_model_score\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e,sys)\n",
    "        \n",
    "    def finetune_best_model(self,\n",
    "                            best_model_object:object,\n",
    "                            best_model_name,\n",
    "                            X_train,\n",
    "                            y_train,\n",
    "                            ) -> object:\n",
    "        \n",
    "        try:\n",
    "\n",
    "            model_param_grid = self.utils.read_yaml_file(self.model_trainer_config.model_config_file_path)[\"model_selection\"][\"model\"][best_model_name][\"search_param_grid\"]\n",
    "\n",
    "\n",
    "            grid_search = GridSearchCV(\n",
    "                best_model_object, param_grid=model_param_grid, cv=5, n_jobs=-1, verbose=1 )\n",
    "            \n",
    "            grid_search.fit(X_train, y_train)\n",
    "\n",
    "            best_params = grid_search.best_params_\n",
    "\n",
    "            print(\"best params are:\", best_params)\n",
    "\n",
    "            finetuned_model = best_model_object.set_params(**best_params)\n",
    "            \n",
    "\n",
    "            return finetuned_model\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise CustomException(e,sys)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def initiate_model_trainer(self, train_array, test_array):\n",
    "        try:\n",
    "            logging.info(f\"Splitting training and testing input and target feature\")\n",
    "\n",
    "            x_train, y_train, x_test, y_test = (\n",
    "                train_array[:, :-1],\n",
    "                train_array[:, -1],\n",
    "                test_array[:, :-1],\n",
    "                test_array[:, -1],\n",
    "            )\n",
    "\n",
    "            \n",
    "\n",
    "            logging.info(f\"Extracting model config file path\")\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            logging.info(f\"Extracting model config file path\")\n",
    "\n",
    "            model_report: dict = self.evaluate_models(X=x_train, y=y_train, models=self.models)\n",
    "\n",
    "            ## To get best model score from dict\n",
    "            best_model_score = max(sorted(model_report.values()))\n",
    "\n",
    "            ## To get best model name from dict\n",
    "\n",
    "            best_model_name = list(model_report.keys())[\n",
    "                list(model_report.values()).index(best_model_score)\n",
    "            ]\n",
    "\n",
    "\n",
    "            best_model = self.models[best_model_name]\n",
    "\n",
    "\n",
    "            best_model = self.finetune_best_model(\n",
    "                best_model_name= best_model_name,\n",
    "                best_model_object= best_model,\n",
    "                X_train= x_train,\n",
    "                y_train= y_train\n",
    "            )\n",
    "\n",
    "            best_model.fit(x_train, y_train)\n",
    "            y_pred = best_model.predict(x_test)\n",
    "            best_model_score = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            print(f\"best model name {best_model_name} and score: {best_model_score}\")\n",
    "\n",
    "\n",
    "            if best_model_score < 0.5:\n",
    "                raise Exception(\"No best model found with an accuracy greater than the threshold 0.6\")\n",
    "            \n",
    "            logging.info(f\"Best found model on both training and testing dataset\")\n",
    "\n",
    " \n",
    "        \n",
    "\n",
    "            logging.info(\n",
    "                f\"Saving model at path: {self.model_trainer_config.trained_model_path}\"\n",
    "            )\n",
    "\n",
    "            os.makedirs(os.path.dirname(self.model_trainer_config.trained_model_path), exist_ok=True)\n",
    "\n",
    "            self.utils.save_object(\n",
    "                file_path=self.model_trainer_config.trained_model_path,\n",
    "                obj=best_model\n",
    "            )\n",
    "            \n",
    "            return self.model_trainer_config.trained_model_path\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28832da9-0c66-4871-9e89-5c6fb8867bff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4932b296-fdeb-4f74-a245-9c12d8be47dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
